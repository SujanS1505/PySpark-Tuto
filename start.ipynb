{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80202b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ASUS:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ee35639960>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d90090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+--------+\n",
      "|    _c0|   _c1|  _c2|   _c3|     _c4|\n",
      "+-------+------+-----+------+--------+\n",
      "|Item_No|Length|Width|Height|Operator|\n",
      "|      1|102.67|49.53| 19.69|    Op-1|\n",
      "|      2| 102.5|51.42| 19.63|    Op-1|\n",
      "|      3| 95.37|52.25| 21.51|    Op-1|\n",
      "|      4| 94.77|49.24|  18.6|    Op-1|\n",
      "|      5|104.26| 47.9| 19.46|    Op-1|\n",
      "|      6|105.18|49.39| 20.36|    Op-1|\n",
      "|      7| 97.35|48.05| 20.22|    Op-1|\n",
      "|      8| 99.35|44.59| 21.03|    Op-1|\n",
      "|      9| 90.62|47.29| 19.78|    Op-1|\n",
      "|     10| 97.22|52.14| 20.71|    Op-1|\n",
      "|     11|   100|54.76| 20.62|    Op-1|\n",
      "|     12| 97.23|48.26| 19.51|    Op-1|\n",
      "|     13|105.72|50.04| 20.06|    Op-1|\n",
      "|     14| 89.82|45.98|  20.3|    Op-1|\n",
      "|     15| 99.17|53.54| 20.25|    Op-1|\n",
      "|     16| 95.51|45.36| 20.52|    Op-1|\n",
      "|     17|107.69|48.18| 19.33|    Op-1|\n",
      "|     18|106.83|50.81| 19.12|    Op-1|\n",
      "|     19| 98.73|55.76| 19.37|    Op-1|\n",
      "+-------+------+-----+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=spark.read.csv(\"D:\\Study\\Centillion\\Pyspark\\Datasets\\Piece_Dimension.csv\")\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419e354",
   "metadata": {},
   "source": [
    "Inorder to get the column name instead of c0,c1,etc, we can use spark.read.option method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c478cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+--------+\n",
      "|Item_No|Length|Width|Height|Operator|\n",
      "+-------+------+-----+------+--------+\n",
      "|      1|102.67|49.53| 19.69|    Op-1|\n",
      "|      2| 102.5|51.42| 19.63|    Op-1|\n",
      "|      3| 95.37|52.25| 21.51|    Op-1|\n",
      "|      4| 94.77|49.24|  18.6|    Op-1|\n",
      "|      5|104.26| 47.9| 19.46|    Op-1|\n",
      "|      6|105.18|49.39| 20.36|    Op-1|\n",
      "|      7| 97.35|48.05| 20.22|    Op-1|\n",
      "|      8| 99.35|44.59| 21.03|    Op-1|\n",
      "|      9| 90.62|47.29| 19.78|    Op-1|\n",
      "|     10| 97.22|52.14| 20.71|    Op-1|\n",
      "|     11|   100|54.76| 20.62|    Op-1|\n",
      "|     12| 97.23|48.26| 19.51|    Op-1|\n",
      "|     13|105.72|50.04| 20.06|    Op-1|\n",
      "|     14| 89.82|45.98|  20.3|    Op-1|\n",
      "|     15| 99.17|53.54| 20.25|    Op-1|\n",
      "|     16| 95.51|45.36| 20.52|    Op-1|\n",
      "|     17|107.69|48.18| 19.33|    Op-1|\n",
      "|     18|106.83|50.81| 19.12|    Op-1|\n",
      "|     19| 98.73|55.76| 19.37|    Op-1|\n",
      "|     20| 94.31|48.74|  18.8|    Op-1|\n",
      "+-------+------+-----+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=spark.read.option(\"header\",\"true\").csv(\"D:\\Study\\Centillion\\Pyspark\\Datasets\\Piece_Dimension.csv\")\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b50cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item_No: string (nullable = true)\n",
      " |-- Length: string (nullable = true)\n",
      " |-- Width: string (nullable = true)\n",
      " |-- Height: string (nullable = true)\n",
      " |-- Operator: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Item_No='1', Length='102.67', Width='49.53', Height='19.69', Operator='Op-1'),\n",
       " Row(Item_No='2', Length='102.5', Width='51.42', Height='19.63', Operator='Op-1'),\n",
       " Row(Item_No='3', Length='95.37', Width='52.25', Height='21.51', Operator='Op-1'),\n",
       " Row(Item_No='4', Length='94.77', Width='49.24', Height='18.6', Operator='Op-1'),\n",
       " Row(Item_No='5', Length='104.26', Width='47.9', Height='19.46', Operator='Op-1')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_spark.printSchema())\n",
    "\n",
    "df_spark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e5262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item_No: integer (nullable = true)\n",
      " |-- Length: double (nullable = true)\n",
      " |-- Width: double (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Operator: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"D:\\Study\\Centillion\\Pyspark\\Datasets\\Piece_Dimension.csv\")\n",
    "df2.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
